{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44832876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 步骤 1: 环境设置与模型定义 ---\n",
      "环境设置完毕。\n",
      "\n",
      "--- 步骤 2: 加载模型 ---\n",
      "成功加载模型权重: best_visual_model.pth\n",
      "模型已设置为评估模式。\n",
      "\n",
      "--- 步骤 3: 准备测试数据 ---\n",
      "原始测试集行数: 5\n",
      "唯一图片数量: 1\n",
      "测试数据准备完毕。\n",
      "\n",
      "--- 步骤 4: 开始预测 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/77ps8s1x14zg2_q9t7f74t4r0000gn/T/ipykernel_62095/3082563257.py:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inference_model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4c9e72a7d64a5e906b85a6baf1e55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "预测中:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测完成。\n",
      "\n",
      "--- 步骤 5: 生成提交文件 ---\n",
      "==================================================\n",
      "提交文件 'submission.csv' 已成功生成！\n",
      "                    sample_id    target\n",
      "0  ID1001187975__Dry_Clover_g  1.249537\n",
      "1    ID1001187975__Dry_Dead_g  2.135950\n",
      "2   ID1001187975__Dry_Green_g  2.854519\n",
      "3   ID1001187975__Dry_Total_g  6.423885\n",
      "4         ID1001187975__GDM_g  4.913448\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#           04_inference_visual.ipynb: 纯视觉模型推理与提交\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"--- 步骤 1: 环境设置与模型定义 ---\")\n",
    "\n",
    "# --- 1. 定义纯视觉模型 VisualModel (ResNet18 版本) ---\n",
    "# 必须与你训练时使用的结构完全一致\n",
    "class VisualModel(nn.Module):\n",
    "    def __init__(self, num_targets=5, pretrained=True):\n",
    "        super(VisualModel, self).__init__()\n",
    "        # 加载 ResNet18\n",
    "        self.cnn = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        num_cnn_features = self.cnn.fc.in_features\n",
    "        # 替换最后一层\n",
    "        self.cnn.fc = nn.Sequential(\n",
    "            nn.Linear(num_cnn_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_targets)\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        output = self.cnn(image)\n",
    "        return output\n",
    "\n",
    "# --- 2. 定义推理数据集类 ---\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 获取图片路径\n",
    "        img_path_rel = self.df.iloc[idx]['image_path']\n",
    "        img_path = os.path.join(self.image_dir, img_path_rel)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except FileNotFoundError:\n",
    "            # 容错处理\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image\n",
    "\n",
    "# --- 3. 定义图像变换 (验证集标准) ---\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"环境设置完毕。\\n\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 步骤 2: 加载训练好的模型\n",
    "# =============================================================================\n",
    "\n",
    "print(\"--- 步骤 2: 加载模型 ---\")\n",
    "\n",
    "MODEL_PATH = 'best_visual_model.pth' \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 实例化模型\n",
    "inference_model = VisualModel().to(device)\n",
    "\n",
    "# 加载权重\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    inference_model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    print(f\"成功加载模型权重: {MODEL_PATH}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"找不到模型文件: {MODEL_PATH}\")\n",
    "\n",
    "inference_model.eval()\n",
    "print(\"模型已设置为评估模式。\\n\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 步骤 3: 准备测试数据\n",
    "# =============================================================================\n",
    "\n",
    "print(\"--- 步骤 3: 准备测试数据 ---\")\n",
    "\n",
    "test_df = pd.read_csv('csiro-biomass/test.csv')\n",
    "\n",
    "# 去重：每张图片只预测一次\n",
    "unique_images_df = test_df[['image_path']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"原始测试集行数: {len(test_df)}\")\n",
    "print(f\"唯一图片数量: {len(unique_images_df)}\")\n",
    "\n",
    "# 创建数据集和加载器\n",
    "IMAGE_DIR = './' \n",
    "test_dataset = InferenceDataset(unique_images_df, IMAGE_DIR, transform=data_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"测试数据准备完毕。\\n\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 步骤 4: 执行预测\n",
    "# =============================================================================\n",
    "\n",
    "print(\"--- 步骤 4: 开始预测 ---\")\n",
    "\n",
    "all_predictions = []\n",
    "target_cols = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader, desc=\"预测中\"):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # 预测 (Log 尺度)\n",
    "        log_preds = inference_model(images)\n",
    "        \n",
    "        # 还原 (Exp 变换)\n",
    "        preds = np.expm1(log_preds.cpu().numpy())\n",
    "        \n",
    "        all_predictions.append(preds)\n",
    "\n",
    "# 合并结果\n",
    "predictions_array = np.concatenate(all_predictions, axis=0)\n",
    "pred_df_wide = pd.DataFrame(predictions_array, columns=target_cols)\n",
    "result_df = pd.concat([unique_images_df, pred_df_wide], axis=1)\n",
    "\n",
    "print(\"预测完成。\\n\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 步骤 5: 生成提交文件\n",
    "# =============================================================================\n",
    "\n",
    "print(\"--- 步骤 5: 生成提交文件 ---\")\n",
    "\n",
    "# 合并回原始 test.csv\n",
    "final_df = pd.merge(test_df, result_df, on='image_path', how='left')\n",
    "\n",
    "# 提取每一行对应的 target 值\n",
    "def get_prediction(row):\n",
    "    return row[row['target_name']] if row['target_name'] in row else 0.0\n",
    "\n",
    "final_df['target'] = final_df.apply(get_prediction, axis=1)\n",
    "\n",
    "# 保存\n",
    "submission_df = final_df[['sample_id', 'target']]\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"提交文件 'submission.csv' 已成功生成！\")\n",
    "print(submission_df.head())\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csiro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
