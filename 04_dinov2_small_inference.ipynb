{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a84fea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨ä½¿ç”¨è®¾å¤‡: cpu\n",
      "å°†åŠ è½½æ¨¡å‹: best_dinov2_small_model.pth\n",
      "æµ‹è¯•é›†åŸå§‹è¡Œæ•°: 5\n",
      "å”¯ä¸€å›¾ç‰‡æ•°é‡: 1\n",
      "æ­£åœ¨åˆå§‹åŒ– DINOv2 æ¶æ„...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/nisikin/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼\n",
      "\n",
      "å¼€å§‹æ¨ç†...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/77ps8s1x14zg2_q9t7f74t4r0000gn/T/ipykernel_63778/418644289.py:116: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3e3ab96a2f46d084e59fbcdb03c1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "è¿›åº¦:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨ç”Ÿæˆ submission.csv ...\n",
      "==================================================\n",
      "ğŸ‰ æˆåŠŸï¼æ–‡ä»¶ 'submission.csv' å·²ç”Ÿæˆã€‚\n",
      "å‰ 5 è¡Œé¢„è§ˆ:\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   0.000184\n",
      "1    ID1001187975__Dry_Dead_g  17.005959\n",
      "2   ID1001187975__Dry_Green_g  31.306974\n",
      "3   ID1001187975__Dry_Total_g  48.736496\n",
      "4         ID1001187975__GDM_g  27.792139\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#           04_dinov2_small_inference.ipynb: DINOv2 æ¨¡å‹æ¨ç†ä¸æäº¤\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. é…ç½®å‚æ•°\n",
    "# -----------------------------------------------------------------------------\n",
    "# !! è¯·ç¡®ä¿è¿™é‡Œçš„æ–‡ä»¶åä¸ä½ è®­ç»ƒä¿å­˜çš„æ¨¡å‹æ–‡ä»¶åä¸€è‡´ !!\n",
    "MODEL_PATH = 'best_dinov2_small_model.pth' \n",
    "\n",
    "IMAGE_DIR = 'csiro-biomass'\n",
    "TEST_CSV = 'csiro-biomass/test.csv'\n",
    "BATCH_SIZE = 32\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "print(f\"å°†åŠ è½½æ¨¡å‹: {MODEL_PATH}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. å®šä¹‰æ¨¡å‹ç»“æ„ (DINOv2 VisualModel)\n",
    "# -----------------------------------------------------------------------------\n",
    "# æ³¨æ„ï¼šæ¨ç†æ—¶çš„æ¨¡å‹å®šä¹‰å¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´\n",
    "class DINOv2VisualModel(nn.Module):\n",
    "    def __init__(self, num_targets=5):\n",
    "        super(DINOv2VisualModel, self).__init__()\n",
    "        \n",
    "        print(\"æ­£åœ¨åˆå§‹åŒ– DINOv2 æ¶æ„...\")\n",
    "        # åŠ è½½ backbone\n",
    "        self.backbone = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
    "        \n",
    "        # Small ç‰ˆæœ¬çš„è¾“å‡ºç»´åº¦æ˜¯ 384\n",
    "        self.embed_dim = 384 \n",
    "        \n",
    "        # å®šä¹‰å›å½’å¤´\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.embed_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_targets)\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        # æå–ç‰¹å¾\n",
    "        features = self.backbone.forward_features(image)['x_norm_clstoken']\n",
    "        # é¢„æµ‹\n",
    "        output = self.head(features)\n",
    "        return output\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. å®šä¹‰æ¨ç†æ•°æ®é›†\n",
    "# -----------------------------------------------------------------------------\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # è·å–ç›¸å¯¹è·¯å¾„\n",
    "        img_path_rel = self.df.iloc[idx]['image_path']\n",
    "        img_path = os.path.join(self.image_dir, img_path_rel)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except FileNotFoundError:\n",
    "            # å®¹é”™å¤„ç†ï¼šç”Ÿæˆå…¨é»‘å›¾ç‰‡\n",
    "            print(f\"è­¦å‘Š: æ‰¾ä¸åˆ°å›¾ç‰‡ {img_path}\")\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. å‡†å¤‡æ•°æ®ä¸æ¨¡å‹\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# å®šä¹‰å›¾åƒå˜æ¢ (éªŒè¯é›†æ ‡å‡†)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# è¯»å–æµ‹è¯•åˆ—è¡¨\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# å»é‡ä¼˜åŒ–ï¼šæ¯å¼ å›¾ç‰‡åªé¢„æµ‹ä¸€æ¬¡\n",
    "unique_images_df = test_df[['image_path']].drop_duplicates().reset_index(drop=True)\n",
    "print(f\"æµ‹è¯•é›†åŸå§‹è¡Œæ•°: {len(test_df)}\")\n",
    "print(f\"å”¯ä¸€å›¾ç‰‡æ•°é‡: {len(unique_images_df)}\")\n",
    "\n",
    "# åˆ›å»ºåŠ è½½å™¨\n",
    "test_dataset = InferenceDataset(unique_images_df, IMAGE_DIR, transform=data_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# å®ä¾‹åŒ–å¹¶åŠ è½½æ¨¡å‹\n",
    "model = DINOv2VisualModel(num_targets=5).to(device)\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    print(\"âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {MODEL_PATH}ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚\")\n",
    "\n",
    "model.eval() # å¼€å¯è¯„ä¼°æ¨¡å¼\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. æ‰§è¡Œæ¨ç†\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nå¼€å§‹æ¨ç†...\")\n",
    "\n",
    "all_predictions = []\n",
    "# ç›®æ ‡åˆ—é¡ºåº (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´)\n",
    "target_cols = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader, desc=\"è¿›åº¦\"):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # 1. æ¨¡å‹é¢„æµ‹ (Log å°ºåº¦)\n",
    "        log_preds = model(images)\n",
    "        \n",
    "        # 2. è¿˜åŸæ•°å€¼ (Exp å˜æ¢)\n",
    "        preds = np.expm1(log_preds.cpu().numpy())\n",
    "        \n",
    "        # 3. é˜²æ­¢è´Ÿå€¼ (ç‰©ç†ä¸Šç”Ÿç‰©é‡ä¸èƒ½ä¸ºè´Ÿï¼Œè™½ç„¶expm1é€šå¸¸>=-1ï¼Œä½†åŠ ä¸ªä¿é™©)\n",
    "        preds = np.maximum(preds, 0)\n",
    "        \n",
    "        all_predictions.append(preds)\n",
    "\n",
    "# åˆå¹¶ç»“æœ\n",
    "predictions_array = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. ç”Ÿæˆæäº¤æ–‡ä»¶\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"æ­£åœ¨ç”Ÿæˆ submission.csv ...\")\n",
    "\n",
    "# 1. å°†é¢„æµ‹ç»“æœè½¬ä¸º DataFrame\n",
    "pred_df_wide = pd.DataFrame(predictions_array, columns=target_cols)\n",
    "# 2. å°†ç»“æœä¸ image_path å…³è”\n",
    "result_df = pd.concat([unique_images_df, pred_df_wide], axis=1)\n",
    "\n",
    "# 3. å°†ç»“æœåˆå¹¶å›åŸå§‹çš„ test.csv (é€šè¿‡ image_path)\n",
    "final_df = pd.merge(test_df, result_df, on='image_path', how='left')\n",
    "\n",
    "# 4. æ ¹æ®æ¯ä¸€è¡Œçš„ target_name æå–å¯¹åº”çš„é¢„æµ‹å€¼\n",
    "def get_prediction(row):\n",
    "    t_name = row['target_name']\n",
    "    if t_name in row:\n",
    "        return row[t_name]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "final_df['target'] = final_df.apply(get_prediction, axis=1)\n",
    "\n",
    "# 5. ä¿å­˜æœ€ç»ˆæ–‡ä»¶\n",
    "submission_df = final_df[['sample_id', 'target']]\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"ğŸ‰ æˆåŠŸï¼æ–‡ä»¶ 'submission.csv' å·²ç”Ÿæˆã€‚\")\n",
    "print(\"å‰ 5 è¡Œé¢„è§ˆ:\")\n",
    "print(submission_df.head())\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csiro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
